{
  "components": {
    "comp-data-ingestion": {
      "executorLabel": "exec-data-ingestion",
      "inputDefinitions": {
        "parameters": {
          "gcs_csv_uri": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "dataset": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-register-model": {
      "executorLabel": "exec-register-model",
      "inputDefinitions": {
        "artifacts": {
          "model_artifact": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "model_bucket": {
            "parameterType": "STRING"
          },
          "project": {
            "parameterType": "STRING"
          },
          "region": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-train-logistic-regression": {
      "executorLabel": "exec-train-logistic-regression",
      "inputDefinitions": {
        "artifacts": {
          "dataset": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "numeric_features_json": {
            "parameterType": "STRING"
          },
          "random_state": {
            "defaultValue": 42.0,
            "isOptional": true,
            "parameterType": "NUMBER_INTEGER"
          },
          "target_col": {
            "defaultValue": "is_churned",
            "isOptional": true,
            "parameterType": "STRING"
          },
          "test_size": {
            "defaultValue": 0.2,
            "isOptional": true,
            "parameterType": "NUMBER_DOUBLE"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "model_artifact": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    }
  },
  "deploymentSpec": {
    "executors": {
      "exec-data-ingestion": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "data_ingestion"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.6.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'gcsfs' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef data_ingestion(gcs_csv_uri: str, dataset: Output[Dataset]):\n    import pandas as pd\n    df = pd.read_csv(gcs_csv_uri)\n    print(\"\u2705 Data loaded:\", df.shape)\n    df.to_csv(dataset.path, index=False)\n\n"
          ],
          "image": "python:3.7"
        }
      },
      "exec-register-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "register_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.6.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-aiplatform' 'gcsfs' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef register_model(\n    project: str,\n    region: str,\n    model_bucket: str,\n    model_artifact: Input[Model],\n):\n    from google.cloud import aiplatform\n    import gcsfs, os\n\n    aiplatform.init(project=project, location=region)\n    fs = gcsfs.GCSFileSystem()\n\n    gcs_model_path = model_bucket.rstrip(\"/\") + \"/spotify_lr_model/model.pkl\"\n    local_model = os.path.join(model_artifact.path, \"model.pkl\")\n\n    # Upload model to your dedicated model bucket\n    with fs.open(gcs_model_path, \"wb\") as f_out, open(local_model, \"rb\") as f_in:\n        f_out.write(f_in.read())\n\n    # Register in Vertex Model Registry\n    model = aiplatform.Model.upload(\n        display_name=\"spotify-churn-lr\",\n        artifact_uri=model_bucket,\n        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-4:latest\",\n        description=\"Spotify churn Logistic Regression numeric-only model\",\n    )\n\n    print(\"\u2705 Model registered in Vertex AI:\", model.resource_name)\n\n"
          ],
          "image": "python:3.7"
        }
      },
      "exec-train-logistic-regression": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "train_logistic_regression"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.6.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pandas' 'scikit-learn==1.4.2' 'joblib' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef train_logistic_regression(\n    dataset: Input[Dataset],\n    model_artifact: Output[Model],\n    metrics: Output[Metrics],\n    numeric_features_json: str,\n    target_col: str = \"is_churned\",\n    test_size: float = 0.2,\n    random_state: int = 42,\n):\n    import json, os, joblib, pandas as pd\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_fscore_support\n\n    NUMERIC_FEATURES = json.loads(numeric_features_json)\n    df = pd.read_csv(dataset.path)\n\n    X = df[NUMERIC_FEATURES]\n    y = df[target_col].astype(int)\n\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=test_size, random_state=random_state, stratify=y\n    )\n\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled  = scaler.transform(X_test)\n\n    model = LogisticRegression(max_iter=200, class_weight=\"balanced\", solver=\"liblinear\")\n    model.fit(X_train_scaled, y_train)\n\n    y_pred = model.predict(X_test_scaled)\n    y_prob = model.predict_proba(X_test_scaled)[:,1]\n\n    acc = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_prob)\n    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\")\n\n    metrics.log_metric(\"accuracy\",  float(acc))\n    metrics.log_metric(\"roc_auc\",   float(auc))\n    metrics.log_metric(\"precision\", float(precision))\n    metrics.log_metric(\"recall\",    float(recall))\n    metrics.log_metric(\"f1\",        float(f1))\n\n    print(\"\u2705 Model Performance:\")\n    print(json.dumps({\"accuracy\":acc,\"roc_auc\":auc,\"precision\":precision,\"recall\":recall,\"f1\":f1},indent=2))\n\n    os.makedirs(model_artifact.path, exist_ok=True)\n    joblib.dump((scaler, model), os.path.join(model_artifact.path, \"model.pkl\"))\n\n"
          ],
          "image": "python:3.7"
        }
      }
    }
  },
  "pipelineInfo": {
    "description": "Spotify Churn Prediction Pipeline (Logistic Regression, numeric-only)",
    "name": "spotify-churn-pipeline-lr"
  },
  "root": {
    "dag": {
      "outputs": {
        "artifacts": {
          "train-logistic-regression-metrics": {
            "artifactSelectors": [
              {
                "outputArtifactKey": "metrics",
                "producerSubtask": "train-logistic-regression"
              }
            ]
          }
        }
      },
      "tasks": {
        "data-ingestion": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-data-ingestion"
          },
          "inputs": {
            "parameters": {
              "gcs_csv_uri": {
                "componentInputParameter": "gcs_csv_uri"
              }
            }
          },
          "taskInfo": {
            "name": "data-ingestion"
          }
        },
        "register-model": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-register-model"
          },
          "dependentTasks": [
            "train-logistic-regression"
          ],
          "inputs": {
            "artifacts": {
              "model_artifact": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "model_artifact",
                  "producerTask": "train-logistic-regression"
                }
              }
            },
            "parameters": {
              "model_bucket": {
                "componentInputParameter": "model_bucket"
              },
              "project": {
                "componentInputParameter": "project"
              },
              "region": {
                "componentInputParameter": "region"
              }
            }
          },
          "taskInfo": {
            "name": "register-model"
          }
        },
        "train-logistic-regression": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-train-logistic-regression"
          },
          "dependentTasks": [
            "data-ingestion"
          ],
          "inputs": {
            "artifacts": {
              "dataset": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "dataset",
                  "producerTask": "data-ingestion"
                }
              }
            },
            "parameters": {
              "numeric_features_json": {
                "runtimeValue": {
                  "constant": "[\"age\", \"listening_time\", \"songs_played_per_day\", \"skip_rate\", \"ads_listened_per_week\"]"
                }
              },
              "target_col": {
                "runtimeValue": {
                  "constant": "is_churned"
                }
              }
            }
          },
          "taskInfo": {
            "name": "train-logistic-regression"
          }
        }
      }
    },
    "inputDefinitions": {
      "parameters": {
        "gcs_csv_uri": {
          "defaultValue": "gs://spotify_data_25/spotify_churn_dataset.csv",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "model_bucket": {
          "defaultValue": "gs://spotify_models",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "project": {
          "defaultValue": "de2025-471807",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "region": {
          "defaultValue": "us-central1",
          "isOptional": true,
          "parameterType": "STRING"
        }
      }
    },
    "outputDefinitions": {
      "artifacts": {
        "train-logistic-regression-metrics": {
          "artifactType": {
            "schemaTitle": "system.Metrics",
            "schemaVersion": "0.0.1"
          }
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.6.0"
}